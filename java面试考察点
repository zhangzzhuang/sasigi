java
### 考察点

* Java基础编程

    * 内存模型、内存结构

        * 内存模型: JMM，原子性、可见性、有序性

        * 内存结构: JVM内存结构

          类加载器(ClassLoader)、运行时数据区(Run time data area)、执行引擎、本地接口

          运行时数据区:

            * 程序计数器、虚拟机栈、本地方法栈、堆、方法区

    * 多线程
        * 实现方式

            * 继承Thread类，重写run方法
            * 实现Runnable接口，重写run方法，实现Runnable接口的实现类的实例对象作为Thread构造函数的target
            * 通过Callable和FutureTask创建线程
            * 通过线程池创建线程

        * 共享变量
        * 线程池
        * 多线程结果聚合

            * CountDownLatch、CycleBarrier等AQS组件的使用

            * Callable 和 FutureTask的使用

        * 线程安全集合， ConcurrentHashMap的实现方式

            * Java7， 使用锁分段技术，将数据分成一段一段的存储，给每一段数据配置一把锁，当一个线程占用锁访问其中一段数据时，其他段的数据也能被其它线程访问

            * Java8，使用synchronized锁住hash后得到的数组下标位置中的第一个元素 ，如下图，这样加锁比segment加锁能支持更高的并发量

        * AtomicInteger

          底层基本上就是通过Usafe和CAS机制来实现的，可以实现数据操作的原子性。有好处也肯定有一个坏处。从好的方面来讲，就是上面AtomicInteger类可以保持其原子性。但是从坏的方面来看，Usafe因为直接操作的底层地址，肯定不是那么安全，而且CAS机制也伴随着大量的问题，比如说有名的ABA问题

    * JVM
        * JVM常用参数

            - -Xms20M : 表示设置JVM启动内存的最小值为20M，必须以M为单位
            - -Xmx20M : 表示设置JVM启动内存的最大值为20M，必须以M为单位。将-Xmx和-Xms设置为一样可以避免JVM内存自动扩展。大的项目-Xmx和-Xms一般都要设置到10G、20G甚至还要高
            - -verbose:gc 表示输出虚拟机中GC的详细情况
            - -Xss128k : 表示可以设置虚拟机栈的大小为128k
            - -XX:NewRatio=4 : 表示设置年轻代：老年代的大小比值为1：4，这意味着年轻代占整个堆的1/5
            - -XX:SurvivorRatio=8 : 表示设置2个Survivor区：1个Eden区的大小比值为2:8，这意味着Survivor区占整个年轻代的1/5，这个参数默认为8
            - -Xmn20M : 表示设置年轻代的大小为20M
            - -Xoss128k : 表示设置本地方法栈的大小为128k。不过HotSpot并不区分虚拟机栈和本地方法栈，因此对于HotSpot来说这个参数是无效的
            - -Xnoclassgc : 表示关闭JVM对类的垃圾回收
            - -XX:+TraceClassLoading : 表示查看类的加载信息
            - -XX:+TraceClassUnLoading : 表示查看类的卸载信息
            - -XX:+PrintGC : 表示在控制台上打印出GC信息

        * OOM问题定位和处理

          **OOM进程信息**

            1. 查看OOM的进程

                   top -d 1 -c 
                   大写M： 内存使用排序

            2. 查看内存是否分配过小

                   jmap -heap pid

            3. 找到最消耗内存的对象

                   jmap -histo:live pid | more

            4. 确认是否资源耗尽

                   （1）ps -efL pid
                   （2）netstat -apn | grep pid
                   （3）ll /proc/pid/fd
                   （4）ll /proc/pid/task

            5. 碎片处理

                   -XX:PrintFLSStatistics
                   jstat -gcutil pid 2s

          **查看错误日志**

                如果存在错误日志，可根据大小或者时间来查看日志ll（ls -l）并处理问题：   

            * 按大小排序：ll -Sh
            * 按时间排序：ll -rt
            * ll -t是降序，ll -t | tac是升序

          **查看堆栈信息**

            * 通过jps命令查看执行的java进程
            * 通过top命令查看耗时的java进程
            * 通过top -Hp pid查看java进程下的线程信息
            * 通过jstack pid命令查看java进程的堆栈信息
            * 将堆栈信息输出到日志文件：jstack pid > jstack.log
            * 查看堆栈信息：view jstack.log
            * 在Thread dump中，可根据线程的状态来分析问题：

                  1、RUNNABLE的线程处于执行中
                  2、BLOCKED的线程被阻塞
                  3、WAITING的线程正在等待

          **JVM堆参数设置**

          JAVA_OPTS="-server -Xms2000m -Xmx2000m -Xmn800m -XX:PermSize=64m -XX:MaxPermSize=256m

          -XX:SurvivorRatio=4

          -verbose:gc -Xloggc:$CATALINA_HOME/logs/gc.log -XX:+PrintGCTimeStamps -XX:+PrintGCDetails

          -Dsun.rmi.dgc.server.gcInterval=600000 -Dsun.rmi.dgc.client.gcInterval=600000 -XX:+UseConcMarkSweepGC

          -XX:MaxTenuringThreshold=15 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath:=/opt/jvmdump"

          **JVM参数分析**

            * -Xms2000m -Xmx2000m -Xmn800m -XX:PermSize=64m -XX:MaxPermSize=256m

              Xms：jvm启动时得JVM初始堆大小

              Xmx：jvm的最大堆大小

              Xmn：新生代的大小

              PermSize：永久代的初始大小

              MaxPermSize：永久代的最大空间。
            * -XX:SurvivorRatio=4

              SurvivorRatio：新生代空间中的Eden区和Survivor区的大小比值，比值大小默认是32；

              Survivor存在from-to两个区，因此Survivor是占整个young genertation的1/34；

            * -verbose:gc -Xloggc:$CATALINA_HOME/logs/gc.log

              将JVM中每次GC的信息写到日志文件中，文件名由file指定，文件格式是平文件且内容和-verbose:gc输出内容相同

            * -XX:+PrintGCTimeStamps -XX:+PrintGCDetails

              设置GC日志的格式
            * -Dsun.rmi.dgc.server.gcInterval=600000 -Dsun.rmi.dgc.client.gcInterval=600000

              指定RMI调用时GC的时间间隔
            * -XX:+UseConcMarkSweepGC -XX:MaxTenuringThreshold=15

              采用并发GC方式【JDK8以上另当别论】，经过15次minor GC后进入年老代

          **总结**

            * 通过对jstack.log的分析，可后续找出异常的代码并修复

            * 可通过设置JVM堆来临时解决OOM问题，获取OOM信息 ：

                  （1）设置JVM参数-XX:+HeapDumpOnOutOfMemoryError，当发生OOM时自动dump出堆信息
                  （2）使用jmap命令：jmap -dump:format=b,file=heap.bin ，通过jps来获取pid
            * 分析OOM信息： mat【eclipse memory analyzer】和JDK的jhat【java heap analyze tool】

        * GC算法

            * 1.标记-清除

                * 流程 - 分为“标记”和“清除”两个阶段：

                      （1）首先标记出所需要回收的对象（引用计数法和可达性分析，两次标记过程）；
                      （2）在标记完成后统一回收所有被标记的对象。

                * 缺点

                      （1）效率问题：标记和清除两个过程的效率不高；
                      （2）空间问题：标记清除后会产生大量不连续的内存碎片，导致以后在程序运行过程中需要分配较大对象时，
                       无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。

            * 2.复制

                * 流程 - 可以解决效率问题，将可用的内存按容量划分为大小相等的两块。

                      （1）每次只使用其中的一块；
                      （2）当这一块用完了，就将还存活的对象复制到另一块上；
                      （3）然后再把已使用的内存空间清理掉。

                * 优点

                      每次对整个半区进行内存回收，避免内存碎片问题，只需移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。

                * 缺点

                      在对象存活率较高的时候，效率低下                      

                * 应用

                      回收新生代，新生代中分为Eden空间和两块较小的Survivor空间，
                      每次使用Eden和其中的一块Survivor。默认Eden：Survivor=8:1，Survivor不够时，老年代内存分配担保。

            * 3.标记-整理

                * 流程

                      （1）首先标记出所需要回收的对象；
                      （2）不直接对可回收对象进行清理，让所有存活的对象都向一端移动；
                      （3）直接清理掉端边界以外的内存。

                * 优点

                      改进了复制算法在对象存活率较高时带来的效率问题；

                * 应用

                      老年代收集（对象存活率较高）

            * 4.分代收集

                * 思想 - 根据对象存活周期的不同将内存划分为新生代和老年代，根据各自的特点采用合适的收集算法。

                      （1）新生代中，每次垃圾收集时都发现有大批对象死去，少量存活，选用复制算法；
                      （2）老年代中，对象存活率高、没有额外空间进行分配担保，使用“标记-清理”或者“标记-整理”。

            * QA

                * 为什么不是1块Survivor空间而是2块？

                  这里涉及到一个新生代和老年代的存活周期的问题，比如一个对象在新生代经历15次GC回收，就可以移到老年代了。问题来了，当我们第一次GC的时候，我们可以把Eden区的存活对象放到Survivor-1空间，但是第二次GC的时候，Survivor-1空间和Eden区的存活对象也需要再次用复制算法，放到Survivor-2空间上，而把刚刚的Survivor-1空间和Eden空间清除。第三次GC时，又把Survivor-2空间和Eden区的存活对象复制到Survivor-1空间，如此反复。

                  所以，这里就需要2块Survivor空间来回倒腾。

                * 为什么Eden空间这么大而Survivor空间要分的少一点？

                    1. 新创建的对象都是放在Eden空间，这是很频繁的，尤其是大量的局部变量产生的临时对象，这些对象绝大部分都应该马上被回收，能存活下来被转移到survivor空间一般不是很多。所以，设置较大的Eden空间和较小的Survivor空间是合理的，大大提高了内存的使用率，缓解了复制算法的缺点。

                    2. 8:1:1这种比例就挺好的，当然这个比例是可以调整的，包括上面的新生代和老年代的1:2的比例也是可以调整的。

                    3. 新的问题又来了，从Eden空间往Survivor空间转移的时候，如果出现Survivor空间不够了怎么办？直接放到老年代去。 有的对象来回在Survivor-1区或者Survivor-2区呆了比如15次，就被分配到老年代Old区；有的对象太大，超过了Eden区，直接被分配在Old区；有的存活对象，放不下Survivor区，也被分配到Old区。如果老年代Old区也被放满了，就是一次大GC即为Major GC (Full GC)。

    * StrongReference、WeakReference、SoftReference和PhantomReference
        * heap中对象有强可及对象、软可及对象、弱可及对象、虚可及对象和不可到达对象。
        * 对heap中java对象的应用，通过三个类可以和gc做简单的交互。
    * Optional， Stream操作，迭代中删除元素

      Optional是为了减少代码中的判空，实现函数式编程

      Stream 操作 : 函数式操作

      迭代中删除元素

        1. for迭代中删除元素会报错 java.util.ConcurrentModificationException

            ```java
            for (String str : list) {
                 if (str.equals("c")) {
                     list.remove(str);
                 }
            }
            ```

        1. 使用迭代器的 iterator.remove(); 删除元素不会报错(推荐使用)

            ```java
            for (Iterator iterator = list.iterator(); iterator.hasNext();) {
                String str = iterator.next();
                if (str.equals("c")) {
                    iterator.remove();
                }
            }
            ```

        1. 使用原始的for循环不会报错，删除元素后变量 i 要减一。

            ```java
            for (int i = 0; i < list.size(); i++) {
                if (list.get(i).equals("c")) {
                    list.remove(list.get(i));
                    i--;
                    continue;
                }
            }
            ```

        1. map迭代删除：

            ```java
            Iterator<Integer> it = map.entrySet().iterator();
            while(it.hasNext()){
                Map.Entry entry=it.next();
                int key=entry.getKey();
                if(key%2==1){
                    System.out.println("delete this: "+key+" = "+key);                
                    //map.put(key, "奇数"); //ConcurrentModificationException                
                    //map.remove(key); //ConcurrentModificationException
                    it.remove(); //OK
                }
            }
            ```                

    * Cache， LRU

        ```java
        /**
         * 实现LRU缓存 - 最近最少使用 使用LinkedHashMap实现
         *
         * @author Baixiaowen
         */
        public class LRUCache<K, V> implements Iterable{
        
            int MAX = 3;
            LinkedHashMap<K, V> cache = new LinkedHashMap<>();
        
            public void cache(K key, V value) {
                if (cache.containsKey(key)) {
                    cache.remove(key);
                } else if (cache.size() >= MAX) {
                    // 如果元素个数超过最大值，删除第一个元素的Key，重新插入新元素
                    Iterator it = cache.keySet().iterator();
                    K first = (K) it.next();
                    cache.remove(first);
                }
                cache.put(key, value);
            }
        
            @Override
            public Iterator iterator() {
        
                Iterator<K> it = cache.keySet().iterator();
                return new Iterator<K>() {
                    @Override
                    public boolean hasNext() {
                        return it.hasNext();
                    }
        
                    @Override
                    public K next() {
                        return it.next();
                    }
                };
            }
        
            public static void main(String[] args) {
                LRUCache<String, Integer> lru = new LRUCache<>();
                lru.cache("A", 1);
                lru.cache("B", 2);
                lru.cache("C", 3);
        
                lru.cache("D", 4);
                lru.cache("C", 10);
                System.err.println(
                        "level <-" +
                        StreamSupport.stream(lru.spliterator(), false)
                                    .map(x -> x.toString())
                        .collect(Collectors.joining("<-"))
                );
            }
        
        }
        ```          

    * 树结构操作，如组织结构树

      前序遍历、中序遍历、后续遍历

      DFS、BFS

* 数据库
    * 事务管理

      ACID: 原子性、一致性、隔离性、持久性

      事务隔离级别: 读未提交(read-uncommited)、读已提交(read-commited)、可重复度(repeated-read)、串行化(serializable)

    * MySQL索引
        * 索引的实现机制

          使用B+树实现，考虑到磁盘 IO 读一个数据和读 100 个数据消耗的时间基本一致，所以尽可能在一次磁盘 IO 中多读一点数据到内存，尽可能少的磁盘 IO，尽可能少的磁盘 IO，可以支持范围查找。

        * 索引的类型

            * fulltext(全文索引)，MyISAM引擎支持

              全文索引并不是和MyISAM一起诞生的，它的出现是为了解决WHERE name LIKE “%word%"这类针对文本的模糊查询效率较低的问题。

            * Hash(Hash索引)

              由于HASH的唯一（几乎100%的唯一）及类似键值对的形式，很适合作为索引。

              HASH索引可以一次定位，不需要像树形索引那样逐层查找,因此具有极高的效率。但是，这种高效是有条件的，即只在“=”和“in”条件下高效，对于范围查询、排序及组合索引仍然效率不高。

            * BTREE

              BTREE索引就是一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口root开始，依次遍历node，获取leaf。这是MySQL里默认和最常用的索引类型。

            * RTREE

              RTREE在MySQL很少使用，仅支持geometry数据类型，支持该类型的存储引擎只有MyISAM、BDb、InnoDb、NDb、Archive几种。

              相对于BTREE，RTREE的优势在于范围查找。

        * 索引的种类

            * 普通索引：仅加速查询

            * 唯一索引：加速查询 + 列值唯一（可以有null）

            * 主键索引：加速查询 + 列值唯一（不可以有null）+ 表中只有一个

            * 联合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并

            * 全文索引：对文本的内容进行分词，进行搜索

          ps.

          索引合并，使用多个单列索引组合搜索

          覆盖索引，select的数据列只用从索引中就能够取得，不必读取数据行，换句话说查询列要被所建的索引覆盖

        * 哪些字段应该加索引，哪些字段不应加索引

            * 1、表的某个字段值得离散度越高，该字段越适合选作索引的关键字。主键字段以及唯一性约束字段适合选作索引的关键字，原因就是这些字段的值非常离散。MySQL 在处理主键约束以及唯一性约束时，考虑周全。数据库用户创建主键约束的同时， MySQL 自动创建主索引( primary index )，且索引名称为 Primary；数据库用户创建唯一性索引时， MySQL 自动创建唯一性索引( unique index )，默认情况下，索引名为唯一性索引的字段名。

            * 2、占用存储空间少的字段更适合选作索引的关键字。例如，与字符串相比，整数字段占用的存储空间较少，因此，较为适合选作索引关键字。

            * 3、存储空间固定的字段更适合选作索引的关键字。与 text 类型的字段相比， char 类型的字段较为适合选作索引关键字。

            * 4、Where 子句中经常使用的字段应该创建索引，分组字段或者排序字段应该创建索引，两个表的连接字段应该创建索引。

            * 5、更新频繁的字段不适合创建索引，不会出现在 where 子句中的字段不应该创建索引。

            * 6、经常与其他表进行连接的表，在连接字段上应该建立索引；

            * 7、索引应该建在选择性高的字段上；

            * 8、索引应该建在小字段上，对于大的文本字段甚至超长字段，不要建索引；

        * MySQL缓存机制， PrepareStatement - Prepare SQL的产生原因与实现原理?

          Prepare SQL也叫预编译SQL、Prepared Statements或者Parameterized Statements，就是将这类SQL中的值用占位符?替代，可以视为将SQL语句模板化或者说参数化。预编译语句的优势在于归纳为：一次编译、多次运行，省去了解析优化等过程。

          Prepare的出现就是为了优化硬解析的问题，Prepare在服务器端的执行过程如下：

          【Prepare】 接收客户端带?的SQL, 硬解析得到语法树(stmt->Lex), 缓存在线程所在的PS cache中。此cache是一个HASH MAP. Key为stmt->id. 然后返回客户端stmt->id等信息。

          【Execute】接收客户端stmt->id和参数等信息(客户端不需要再发SQL过来)。服务器根据stmt->id在PS cache中查找得到硬解析后的stmt, 并设置参数，就可以继续后面的优化和执行。

          Prepare在execute阶段可以节省硬解析的时间。因此prepare适用于频繁执行的SQL

          Prepare的另一个作用是防止SQL注入，这个是纯客户端JDBC通过转义实现的。这也是一般更推荐使用PreparedStatement而不是Statement的主要理由。防SQL注入的具体实现可以参见MySQL驱动中com.mysql.jdbc.PreparedStatement.setString代码。

    * 数据库访问框架
        * jdbc

          JDBC连接数据库的步骤

            * 1、加载驱动。Class.forName("com.mysql.jdbc.Driver");显示加载到JVM中
            * 2、建立连接
            * 3、创建预编译PrepareStatement对象
            * 4、执行SQL语句
            * 5、处理ResultSet结果集
            * 6、关闭资源

        * MyBatis

          Mybatis常见面试题: https://blog.csdn.net/weixin_44395707/article/details/106328597

        * JPA
        * Spring jdbcTemplate
    * 数据库连接池

      c3p0

          优点是功能简单易用，稳定性好。 缺点就是性能差，由于其架构设计过于复杂，重构成了一件很难的事，因此性能上的缺点，让它失去了大多数用户的使用。

      dbcp

          DBCP(DataBase connection pool)数据库连接池是 apache 上的一个Java连接池项目。
          
          DBCP通过连接池预先同数据库建立一些连接放在内存中(即连接池中)，应用程序需要建立数据库连接时直接到从接池中申请一个连接使用，
          用完后由连接池回收该连接，从而达到连接复用，减少资源消耗的目的。

      HikariCP

          HiKariCP是数据库连接池的一个后起之秀，号称性能最好
          SpringBoot2.0默认使用 HikariCP数据源

      Druid

          它的优点在于强大的监控功能，可以清楚的知道 连接池和SQL的工作情况，方便扩展。

      总结:

          性能方面 hikariCP>druid>tomcat-jdbc>dbcp>c3p0 
          
          druid功能最为全面，sql拦截等功能，统计数据较为全面，具有良好的扩展性
          
          综合以上我们目前系统用的是阿里巴巴的数据库连接池 druid          

    * 数据库主从架构
        * 主从同步
        * 主从路由

    * 分表分库
        * 路由机制
        * 扩容机制
        * 分区表

    * MySQL常用SQL
    * MySQL Group By，Distinct等聚合函数
    * MySQL 各种Join
    * MySQL性能优化
* Spring
    * Spring Bean
    * Spring AOP
    * Spring IOC
    * SpringMVC
* Web应用处理流程
    * Http请求流程
    * Http Method Status
    * CORS  跨域
    * CSRF  跨站请求伪造
    * SSO  OAuth2 用户登录流程
    * 权限管控 RBAC  基于角色的权限访问控制
* 分布式系统
    * CAP
    * BASE
    * 一致性Hash
* Redis
* ES
* 基础算法
* 知识面
    * 从系统A大批量传输数据到系统B，有哪些方法？ 比如MySQL的数据同步到ES或Hive，同构有些什么方法，异构有些什么方法？

      https://www.jianshu.com/p/c3faa26bc221

    * 系统间通信，可以采用哪些协议，分别有什么优缺点，适用于什么场景？

    * 大型复杂系统包含很多子系统，有哪些情况可能导致子系统间数据不一致？有哪些方法来避免或解决子系统之间的数据不一致问题？
    * 在系统迭代演进过程中，业务复杂性问题





